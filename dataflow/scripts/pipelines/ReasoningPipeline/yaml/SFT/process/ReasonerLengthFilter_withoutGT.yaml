model_cache_path: '../ckpt' # Path to cache models
dependencies: [text]
output_file: "demos/demos_result/math/pipeline_withoutGT/length_step7.jsonl"
use_hf: False # Whether to use huggingface_dataset, if used, ignore the local data path below
dataset_name: 'yahma/alpaca-cleaned'
dataset_split: 'train'  
name: 'default' 
revision: null
input_file: 'demos/demos_result/math/pipeline_withoutGT/format_step6.jsonl'  # Local data path, supports json, jsonl, parquet formats
formatter: "TextFormatter" # Data loader type
input_keys: 'pseudo_correct_solution_example'
max_answer_token_length: 8192
tokenizer_dir: 'Qwen/Qwen2.5-0.5B-Instruct'
