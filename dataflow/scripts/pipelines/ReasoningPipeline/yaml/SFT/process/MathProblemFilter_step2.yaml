model_cache_path: '../ckpt' # Path to cache models
dependencies: [text]
output_file: "demos/demos_result/math/pipeline_Q/Corrected_step2.jsonl"

use_hf: False # Whether to use huggingface_dataset, if used, ignore the local data path below
input_file: 'demos/demos_result/math/pipeline_Q/generated_step1.jsonl'  # Local data path, supports json, jsonl, parquet formats
formatter: "TextFormatter" # Data loader type
input_key: "data"
input_question_key: 'instruction'
max_worker: 100
api_args:
  model_name: 'gpt-4o'
  api_url: 'http://123.129.219.111:3000/v1/chat/completions' 
  mode_test: True